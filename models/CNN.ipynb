{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e4624551",
   "metadata": {},
   "source": [
    "# Convolutional Neural Network (CNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dd897d7",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bb2bba6",
   "metadata": {},
   "source": [
    "Load the libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af7e37fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.metrics import roc_curve, auc, confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "from sklearn.preprocessing import label_binarize\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import layers\n",
    "from keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from imblearn.under_sampling import RandomUnderSampler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "354fbd58",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8893cceb",
   "metadata": {},
   "source": [
    "Load the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2641bd9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"data/000webhost_subset_classifed_featureExtracted.csv\", error_bad_lines=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c26cab6e",
   "metadata": {},
   "source": [
    "Split the data into training and testing sets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63ece508",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X = data.drop(columns=[\"password\", \"strength\", \"length\", \"uppercase\", \"lowercase\", \"digits\", \"special\", \"cracking_time\"])\n",
    "#X = X[['entropy', 'levenshtein_distance', 'char_repetition_weight_sum', \"consecutive_char_type\", \"most_common_char_type\", \"char_freq_ratio\", \"password_length_ratio_to_unique_val\", 'bigram_freq', 'trigram_freq', 'fourgram_freq']]\n",
    "X = data.drop(columns=[\"password\", \"strength\", \"length\", \"uppercase\", \"lowercase\", \"digits\", \"special\", \"consecutive_char_type_count\", \"cracking_time\"])\n",
    "y = data[\"strength\"]\n",
    "\n",
    "rus = RandomUnderSampler(random_state=42)\n",
    "X_resampled, y_resampled = rus.fit_resample(X, y)\n",
    "\n",
    "# First, split the data into training and testing sets.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)\n",
    "\n",
    "# Then, split the training set again to create a validation set.\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fecfe91",
   "metadata": {},
   "source": [
    "Categorize the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f16402",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = LabelEncoder()\n",
    "y_train_encoded = encoder.fit_transform(y_train)\n",
    "y_val_encoded = encoder.fit_transform(y_val)\n",
    "y_test_encoded = encoder.fit_transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d3d812a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_reshaped = X_train.values.reshape(X_train.shape[0], X_train.shape[1], 1)\n",
    "X_val_reshaped = X_val.values.reshape(X_val.shape[0], X_val.shape[1], 1)\n",
    "X_test_reshaped = X_test.values.reshape(X_test.shape[0], X_test.shape[1], 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccf21685",
   "metadata": {},
   "source": [
    "## Model Construction and Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eef47cd7",
   "metadata": {},
   "source": [
    "Build the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac007a7e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=(X_train.shape[1], 1)),\n",
    "        layers.Conv1D(32, kernel_size=3, activation='relu'),\n",
    "        layers.MaxPooling1D(pool_size=2),  # Change pool_size from 4 to 2\n",
    "        layers.Conv1D(8, kernel_size=2, activation='relu'),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(128, activation='relu'),\n",
    "        layers.Dense(64, activation='relu'),\n",
    "        layers.Dense(32, activation = 'relu'),\n",
    "        layers.Dense(4, activation='softmax')\n",
    "    ]\n",
    ")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82c60aea",
   "metadata": {},
   "source": [
    "Compile and fit the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9d0898e",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "epochs = 50\n",
    "\n",
    "optimizer = Adam(learning_rate=0.0005)\n",
    "\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])\n",
    "training_history = model.fit(X_train_reshaped, y_train_encoded, batch_size=batch_size, epochs=epochs, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc138097",
   "metadata": {},
   "source": [
    "Validate the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caaab737",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loss, val_acc = model.evaluate(X_val_reshaped, y_val_encoded)\n",
    "print(f\"Val accuracy: {val_acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc92f822",
   "metadata": {},
   "source": [
    "Test the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d4a174e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc = model.evaluate(X_test_reshaped, y_test_encoded)\n",
    "print(f\"Test accuracy: {test_acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8150af3e",
   "metadata": {},
   "source": [
    "Save the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c41471e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"cnn_model.h5\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8ecb11d",
   "metadata": {},
   "source": [
    "# Analysis of the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cdfbcc7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e8d7c40c",
   "metadata": {},
   "source": [
    "Load the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec36a48d",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = load_model(\"cnn_model.h5\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53c097c6",
   "metadata": {},
   "source": [
    "Create a diagram of the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c037e3bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(loaded_model, to_file='CNN.png', show_shapes=True, show_layer_names=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51ccfdcf",
   "metadata": {},
   "source": [
    "Test the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2a90601",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc = loaded_model.evaluate(X_test, y_test_encoded)\n",
    "print(f\"Test accuracy: {test_acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30970b35",
   "metadata": {},
   "source": [
    "Predict on the test set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69a550ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = model.predict(X_test)\n",
    "y_test_pred_classes = np.argmax(y_test_pred, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4be9553",
   "metadata": {},
   "source": [
    "Calculate different performance metrics. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f61a7fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision = precision_score(y_test_encoded, y_test_pred_classes, average='weighted')\n",
    "recall = recall_score(y_test_encoded, y_test_pred_classes, average='weighted')\n",
    "f1 = f1_score(y_test_encoded, y_test_pred_classes, average='weighted')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2da4f8b",
   "metadata": {},
   "source": [
    "Print the metrics. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "762bee8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1-score: {f1}\")\n",
    "print(classification_report(y_test_encoded, y_test_pred_classes))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60366b18",
   "metadata": {},
   "source": [
    "Find the ROC and AUC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af998e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = 4\n",
    "y_test_binarized = label_binarize(y_test_encoded, classes=[0, 1, 2, 3])\n",
    "fpr, tpr, roc_auc = dict(), dict(), dict()\n",
    "\n",
    "for i in range(n_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_test_binarized[:, i], y_test_pred[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f27f921",
   "metadata": {},
   "source": [
    "Plot the ROC curve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0957d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the macro-average AUC\n",
    "auc_macro = sum(roc_auc.values()) / len(roc_auc)\n",
    "print(\"Macro-average AUC:\", auc_macro)\n",
    "\n",
    "# Plot the ROC curves with AUC values\n",
    "plt.figure()\n",
    "for i in range(n_classes):\n",
    "    plt.plot(fpr[i], tpr[i], label=f'Class {i} (AUC = {roc_auc[i]:.2f}')\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('CNN ROC')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.savefig(\"CNN ROC\", dpi=300, bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b93e791e",
   "metadata": {},
   "source": [
    "Rank the features by importance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a34a7be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def permutation_feature_importance(model, X_test, y_test_encoded):\n",
    "    X_test = X_test.to_numpy()  # Convert X_test to a NumPy array\n",
    "\n",
    "    # Calculate the baseline performance\n",
    "    baseline_accuracy = accuracy_score(y_test_encoded, np.argmax(model.predict(X_test), axis=1))\n",
    "\n",
    "    # Initialize an array to store feature importances\n",
    "    feature_importances = np.zeros(X_test.shape[1])\n",
    "\n",
    "    # For each feature\n",
    "    for i in range(X_test.shape[1]):\n",
    "        # Create a copy of the test data with the feature values shuffled\n",
    "        X_test_shuffled = X_test.copy()\n",
    "        X_test_shuffled[:, i] = shuffle(X_test_shuffled[:, i])\n",
    "\n",
    "        # Calculate the performance of the model using the shuffled test data\n",
    "        shuffled_accuracy = accuracy_score(y_test_encoded, np.argmax(model.predict(X_test_shuffled), axis=1))\n",
    "\n",
    "        # Calculate the feature importance as the difference between the baseline and shuffled accuracy\n",
    "        feature_importances[i] = baseline_accuracy - shuffled_accuracy\n",
    "\n",
    "    return feature_importances\n",
    "\n",
    "cnn_feature_importance = permutation_feature_importance(loaded_model, X_test, y_test_encoded)\n",
    "cnn_feature_rank = np.argsort(cnn_feature_importance)[::-1]\n",
    "\n",
    "print(\"CNN feature importance ranking:\")\n",
    "for i, rank in enumerate(cnn_feature_rank):\n",
    "    print(f\"Feature {rank}: {cnn_feature_importance[rank]:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6353c517",
   "metadata": {},
   "source": [
    "Plot the training loss. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae8219f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_loss(history, epoch_interval, model_name):\n",
    "    epochs = range(1, len(history.history['loss']) + 1, epoch_interval)\n",
    "    train_loss = history.history['loss'][::epoch_interval]\n",
    "    val_loss = history.history['val_loss'][::epoch_interval]\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(epochs, train_loss, 'bo', label='Training loss')\n",
    "    plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
    "    plt.title(f'{model_name} - Training and validation loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.savefig(\"CNN Training and Validation Loss\", dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "plot_loss(training_history, 10, 'CNN')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daab9df8",
   "metadata": {},
   "source": [
    "Plot the confusion matrix. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b623f9d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(y_true, y_pred, class_names):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    sns.heatmap(cm_normalized, annot=True, cmap='Blues', fmt='.2f', xticklabels=class_names, yticklabels=class_names)\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.title('CNN Confusion Matrix')\n",
    "    plt.savefig(\"CNN Confusion Matrix\", dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    return(cm)\n",
    "    \n",
    "cm = plot_confusion_matrix(y_test_encoded, y_test_pred_classes, ['Weak', 'Medium', 'Strong', 'Very strong'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d4ac4ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb1d3789",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba024cd5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
