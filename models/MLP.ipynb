{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "24df5b55",
   "metadata": {},
   "source": [
    "# Multilayer Perceptron (MLP)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67026eda",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92590011",
   "metadata": {},
   "source": [
    "Load the libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dfa12c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow import keras\n",
    "from keras import regularizers\n",
    "from keras.optimizers import Adam\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc, confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from imblearn.under_sampling import RandomUnderSampler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2dbc1e9",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faada28b",
   "metadata": {},
   "source": [
    "Load the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fa6cfc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"data/000webhost_subset_classifed_featureExtracted.csv\", error_bad_lines=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3433175",
   "metadata": {},
   "source": [
    "Split the data into traning and testing sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c7510df",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop(columns=[\"password\", \"strength\", \"length\", \"uppercase\", \"lowercase\", \"digits\", \"special\", \"consecutive_char_type_count\", \"cracking_time\"])\n",
    "y = data[\"strength\"]\n",
    "\n",
    "rus = RandomUnderSampler(random_state=42)\n",
    "X_resampled, y_resampled = rus.fit_resample(X, y)\n",
    "\n",
    "# First, split the data into training and testing sets.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)\n",
    "\n",
    "# Then, split the training set again to create a validation set.\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "637d1209",
   "metadata": {},
   "source": [
    "Categorize the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95da9a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = LabelEncoder()\n",
    "y_train_encoded = encoder.fit_transform(y_train)\n",
    "y_val_encoded = encoder.fit_transform(y_val)\n",
    "y_test_encoded = encoder.fit_transform(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a52e4a8",
   "metadata": {},
   "source": [
    "## Model Construction and Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f60122cd",
   "metadata": {},
   "source": [
    "Build the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5274cf7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=(X_train.shape[1], )),\n",
    "        layers.Dense(512, activation='relu'),\n",
    "        layers.Dropout(0.1),\n",
    "        layers.Dense(256, activation='relu'),\n",
    "        layers.Dense(128, activation='relu'),\n",
    "        layers.Dropout(0.1),\n",
    "        layers.Dense(64, activation='relu', kernel_regularizer=regularizers.l1(0.01)),\n",
    "        layers.Dense(32, activation='relu'),\n",
    "        layers.Dropout(0.1),\n",
    "        layers.Dense(16, activation='relu'),\n",
    "        layers.Dense(8, activation='relu'),\n",
    "        layers.Dense(4, activation='softmax')\n",
    "    ]\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f04de150",
   "metadata": {},
   "source": [
    "Compile and fit the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b2cddbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "epochs = 50\n",
    "\n",
    "# Create the Adam optimizer with the desired learning rate\n",
    "optimizer = Adam(learning_rate=0.0005)\n",
    "\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])\n",
    "training_history = model.fit(X_train, y_train_encoded, batch_size=batch_size, epochs=epochs, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2b32763",
   "metadata": {},
   "source": [
    "Run the model on the validation set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad7bbc62",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loss, val_acc = model.evaluate(X_val, y_val_encoded)\n",
    "print(f\"Test accuracy: {val_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c569ace",
   "metadata": {},
   "source": [
    "Save the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d9f0e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"mlp_model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8904fb52",
   "metadata": {},
   "source": [
    "# Analysis of the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7d4ab8b",
   "metadata": {},
   "source": [
    "Load the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a28a4267",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = load_model(\"mlp_model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf0a2e50",
   "metadata": {},
   "source": [
    "Create a diagram of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d89b3e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(loaded_model, to_file='MLP.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88ac2b54",
   "metadata": {},
   "source": [
    "Test the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "306c1856",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc = loaded_model.evaluate(X_test, y_test_encoded)\n",
    "print(f\"Test accuracy: {test_acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b58f15e2",
   "metadata": {},
   "source": [
    "Predict on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c21b9cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = loaded_model.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c3aa39d",
   "metadata": {},
   "source": [
    "Calculate different performance metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af87d730",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision = precision_score(y_test_encoded, y_pred_classes, average='weighted')\n",
    "recall = recall_score(y_test_encoded, y_pred_classes, average='weighted')\n",
    "f1 = f1_score(y_test_encoded, y_pred_classes, average='weighted')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60ee7942",
   "metadata": {},
   "source": [
    "Print the metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d7b7364",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1-score: {f1}\")\n",
    "print(classification_report(y_test_encoded, y_pred_classes))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8569ec19",
   "metadata": {},
   "source": [
    "Find the ROC and AUC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70d7a504",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = 4\n",
    "y_test_binarized = label_binarize(y_test_encoded, classes=[0, 1, 2, 3])\n",
    "fpr, tpr, roc_auc = dict(), dict(), dict()\n",
    "\n",
    "for i in range(n_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_test_binarized[:, i], y_pred[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55b506bb",
   "metadata": {},
   "source": [
    "Plot the ROC curve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bb30e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the macro-average AUC\n",
    "auc_macro = sum(roc_auc.values()) / len(roc_auc)\n",
    "print(\"Macro-average AUC:\", auc_macro)\n",
    "\n",
    "# Plot the ROC curves with AUC values\n",
    "plt.figure()\n",
    "for i in range(n_classes):\n",
    "    plt.plot(fpr[i], tpr[i], label=f'Class {i} (AUC = {roc_auc[i]:.2f}')\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('MLP ROC')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.savefig(\"MLP ROC\", dpi=300, bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65e03f27",
   "metadata": {},
   "source": [
    "Rank the features by importance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29228640",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the absolute values of the weights in the input layer\n",
    "mlp_weights_abs = np.abs(loaded_model.layers[0].get_weights()[0])\n",
    "\n",
    "# Sum the weights across neurons\n",
    "mlp_feature_importance = np.sum(mlp_weights_abs, axis=1)\n",
    "\n",
    "# Rank the features by their importance\n",
    "mlp_feature_rank = np.argsort(mlp_feature_importance)[::-1]\n",
    "\n",
    "print(\"MLP feature importance ranking:\")\n",
    "for i, rank in enumerate(mlp_feature_rank):\n",
    "    print(f\"Feature {rank}: {mlp_feature_importance[rank]:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52feb038",
   "metadata": {},
   "source": [
    "Plot the history. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b5d2334",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_loss(history, epoch_interval, model_name):\n",
    "    epochs = range(1, len(history.history['loss']) + 1, epoch_interval)\n",
    "    train_loss = history.history['loss'][::epoch_interval]\n",
    "    val_loss = history.history['val_loss'][::epoch_interval]\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(epochs, train_loss, 'bo', label='Training loss')\n",
    "    plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
    "    plt.title(f'{model_name} - Training and validation loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.savefig(\"MLP Training and Validation Loss\", dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "plot_loss(training_history, 5, 'MLP')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37c006b0",
   "metadata": {},
   "source": [
    "Plot a confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f29f3cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(y_true, y_pred, class_names):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    sns.heatmap(cm_normalized, annot=True, cmap='Blues', fmt='.2f', xticklabels=class_names, yticklabels=class_names)\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.title('MLP Confusion Matrix')\n",
    "    plt.savefig(\"MLP Confusion Matrix\", dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    return(cm)\n",
    "    \n",
    "cm = plot_confusion_matrix(y_test_encoded, y_pred_classes, ['Weak', 'Medium', 'Strong', 'Very strong'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c5c338c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
